import streamlit as st
import tempfile
import os
from utils import parse_pdf, chat_with_ai # å¯¼å…¥æˆ‘ä»¬åˆšæ‰å†™çš„å‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(page_title="ScholarLens v1.0", layout="wide")
st.title("ğŸ“ ScholarLens: æ™ºèƒ½è®ºæ–‡é˜…è¯»å™¨")
st.caption("Week 1 Project: Built with LlamaParse & DeepSeek")

# åˆå§‹åŒ– Session State (ç”¨æ¥å­˜è§£æå¥½çš„æ–‡æœ¬ï¼Œé˜²æ­¢æ¯æ¬¡åˆ·æ–°éƒ½é‡æ–°è§£æ)
if "parsed_content" not in st.session_state:
    st.session_state.parsed_content = ""

# --- ä¾§è¾¹æ ï¼šä¸Šä¼ åŒº ---
with st.sidebar:
    st.header("ğŸ“„ ä¸Šä¼ è®ºæ–‡")
    uploaded_file = st.file_uploader("é€‰æ‹© PDF æ–‡ä»¶", type=["pdf"])
    
    if uploaded_file and not st.session_state.parsed_content:
        if st.button("å¼€å§‹è§£æ"):
            with st.spinner("æ­£åœ¨è¯·æ±‚ LlamaCloud è¿›è¡Œæ·±åº¦è§£æ... (å¯èƒ½éœ€è¦åå‡ ç§’)"):
                # 1. ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name
                
                # 2. è°ƒç”¨æˆ‘ä»¬åœ¨ utils é‡Œå†™çš„å‡½æ•°
                try:
                    text = parse_pdf(tmp_path)
                    st.session_state.parsed_content = text
                    st.success("è§£ææˆåŠŸï¼")
                except Exception as e:
                    st.error(f"è§£æå¤±è´¥: {e}")
                
                # 3. æ¸…ç†åƒåœ¾
                os.remove(tmp_path)

# --- ä¸»ç•Œé¢ï¼šå±•ç¤ºä¸é—®ç­” ---
if st.session_state.parsed_content:
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ è§£æç»“æœé¢„è§ˆ (Markdown)")
        # æ”¾å…¥ä¸€ä¸ªæ»šåŠ¨æ¡†æŸ¥çœ‹åŸæ–‡
        st.text_area("åŸæ–‡å†…å®¹", st.session_state.parsed_content, height=600)
        
    with col2:
        st.subheader("ğŸ’¬ AI é—®ç­”")
        # ç®€å•çš„èŠå¤©ç•Œé¢
        user_query = st.text_input("å‘è®ºæ–‡æé—® (ä¾‹å¦‚ï¼šè¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ)")
        
        if st.button("å‘é€") and user_query:
            with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                answer = chat_with_ai(st.session_state.parsed_content, user_query)
                st.markdown("### ğŸ¤– å›ç­”")
                st.write(answer)

else:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF å¹¶ç‚¹å‡»è§£æ")